<!DOCTYPE html>
<html lang="en-us">
    <head>
        

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Sharing the progress of an amateur data scientist</title>
        
        <style>

    html body {
        font-family: 'Raleway', sans-serif;
        background-color: PT Sans;
    }

    :root {
        --accent: grey;
        --border-width:  5px ;
    }

</style>


<link rel="stylesheet" href="/css/main.css">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">





<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
 






<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<script>$(document).on('click', function() { $('.collapse').collapse('hide'); })</script>
 <meta name="generator" content="Hugo 0.63.2" />
        

        

        
            <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        

        

    </head>

    <body>
        

        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand visible-xs" href="#">Sharing the progress of an amateur data scientist</a>
                    <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                </div>
                <div class="collapse navbar-collapse">
                    
                        <ul class="nav navbar-nav">
                            
                                <li><a href="/">Home</a></li>
                            
                                <li><a href="/about/">About</a></li>
                            
                                <li><a href="/post/">Posts</a></li>
                            
                        </ul>
                    
                    
                        <ul class="nav navbar-nav navbar-right">
                            
                                <li class="navbar-icon"><a href="mailto:me@example.com"><i class="fa fa-envelope-o"></i></a></li>
                            
                                <li class="navbar-icon"><a href="https://www.linkedin.com/in/username/"><i class="fa fa-linkedin"></i></a></li>
                            
                        </ul>
                    
                </div>
            </div>
        </nav>


<main>

    <div>
        <h2>Sharing the progress of an amateur data scientist</h2>
        <h5>May 13, 2021</h5>
        

    </div>

    <div align="start" class="content">


<p>It has been over half a year since my last blog post and I think it’s time to end the post drought. Ever since I started this blog, I was planning to write a post every time I finish a course from the Data Science specialization or everytime I have exiting results to share. In August 2020, I started the “Practical Machine Learning” course. The material is challenging for someone who encounters the algorithms for the first time, for a data scientiest newbie the course can’t be done in 4 weeks, progress is made slowly and that somehow produced in me some disastisfaction and demotivation. So, I thought to myself, I’ll wait a little bit more until I have some exciting results to share. Many months have passed, and I’m not done with it yet. Now, what about this blog post? About two months ago I run into the youtube channel of Ali Abdaal, who in this <a href="https://www.youtube.com/watch?v=hv1gOEY3cs4&amp;t=251s">youtube video</a> talks about 3 books that changed his life, one of them was “Show your work” from Austin Kleon. Kleon writes in his book that sharing the progress is equally valueable specially in the stage, where there’s still lots of learning and the results of any projects are difficult report. In this digital age, not only experts contribute to the information pool, but also amateurs can contribute to something.“Amateurs might lack formal training, but they’re all lifelong learners, and they make a point of learning in the open so that others can learn from their failures and successes(…). Amateurs are not afraid to make mistake or look ridiculous in public. They’re in love, so they don’t hesitate to do work that others think of as silly or just plain stupid (…). Because they have little to lose, amateurs are willing to try anything and share the results.” Based on this definition of <em>amateur</em>, I will from now on consider myself an amateur data scientist and share in this blog post my experience learning the algorithms and how my motivation fluctuated througout the course. This post is addressed to my future me or some other <em>amateur</em> out there who is going through a stage in learning, when learning is just happening very slowly.</p>
<p>The Practical Machine Learning course is the 8th course from the Data Science Specialization and so far the most interesting course. Week 1 introduces the concepts of prediciton, types of errors and cross validation. Week 2 explains the caret package in R which can be used to separate the data in training and testing set. The package also have the required functions to train the data withe different types of algorithms and make predictions. Week 3 introduces trees, random trees and Model Based predictions. Week 4 explains regularized regressions, combining predictors to make a more accurate model, some forecasting with time series and a quick overview to unsupervised learning. At the end of each week you have as usual a small quizz with 5 questions. However, in most of the cases the questions in the quizz don’t cover the material learned during the week, but it rather ask you to do new things, so be prepared to do some googleing.
The course covers indeed a large variety of concepts or algorithms, and thus, it doesn’t explain the math behind the algorithms and the output of the R code is not throughoutly explained. The slides make a good job to reference to plenty of external resources such as books and other websites. I looked into the books “An Introduction to Statistical Learning” by James, Witten, Hastie and Tibshirani and “The Elements of Statistical Learning” by Hastie, Tibshirani and Friedman and both are really great to learn the maths in the algorithms. The course is great for someone who has experience working with different types of algorithms. Nevetheless, for someone encountering this material for the first time, it is hard to follow the videos and understand everything.</p>
<p>If you find the books too difficult to understand, Josh Starmer uses little math to provide “StatQuest” amazing explanation and intuition behind the algorithms in his youtube channel. Here you can find the link to his channel “<a href="https://www.youtube.com/user/joshstarmer" class="uri">https://www.youtube.com/user/joshstarmer</a>”. For me, it took me a lot of time to work through each algorithm and really understand what the algorithm is doing. I must also say, that I still don’t feel quite confidente with all algorithms explained in the course. The quizzes in the course don’t really test what the videos showed you, but rather other concepts. So, just feel prepared to invest a lot of time in the quizzes. The X minutes mentioned there won’t be enough.</p>
<p>For someone encountering the material for the first time, it is pretty challenging to follow just the quick peek of the R-code, because I also
want to understand how the algorithm works and what is the math behind it. At the beginning of the course I was googleing a lot and bought
two books “An Introduction to Statistical Learning” by James, Witten, Hastie and Tibshirani and “The Elements of Statistical Learning” by Hastie, Tibshirani and Friedman. Found a the youtube channel where the different algorithms where explained in way more detail.
I felt pretty demotivated because I wasn’t make the progress I was planning to and thought I felt kind of overwhelmed because the course
says to take only 1 week to undertand a large variety of algorithms.</p>
<p>All these past months I was thinking “well, I’ll read the next post as soon as I’m done with the course”. But getting the “done” part was always delayed because I needed to google and read a lot to understand the material. Additionally, I wanted to get to a point where I was satistfied with the explanation of the algorithm. This delay really demotivated me and I ended up in a demotivation loop.</p>
<p>I got into the demotivation loop, was dissappointed with coursera and continue reading by myself. But was demotivated to keep reading by
myself because I was expecting the course the teach me the things I needed. I lost momentum.
I am not sure at which point I came out of the dissapointment and demotivation loop, but I think I came out from the bad loop and I am now back on track. Motivation is back and hope to keep posting regularly again.</p>
<p>In March, I found this youtube video from (…) where he introduces the book “Show your work” from Austin kleon. The book is amazing to get some inspiration and motivation. Showing progress of my work is as valuable as showing the final result of my work. So, this really motivated me to write this post and end the drought of posts.</p>
<ol style="list-style-type: decimal">
<li>Don’t try to understand the whole algorithm at once. Break it down. If you’re working with a book, read one page a day.</li>
<li>Google the concepts. A lot of people went through the same. They have already found a solution to your problems.</li>
<li>When you’re demotivated, try doing some small and easy tasks instead Such as watching the video
about the things you’re learning.</li>
<li>Don’t expect to come out of the demotivation loop by doing nothing, that won’t happen. The only way to get out of the demotivation loop is by doing a little bit every day.
“Waiting for inspiration is just a terrible habit”</li>
</ol>
<p>It is quite difficult to build up the habit of learning every day just a little bit when you also have a full-time job and I wasn’t able to do a little bit every day. The momentum comes and goes, so it not a good strategy to trust the momentum. Instead, build the habit.</p>
<p>What I am most happy about: Even though I haven’t been able to work a little bit every day, I can look at the past year and reflect about the things I’ve learned. I’m really proud of myself of the new concepts.</p>
</div>

    
    
    

    
    

</main>

        <footer>
            <p class="copyright text-muted">© All rights reserved. Powered by <a href="https://gohugo.io">Hugo</a> and <a href="https://github.com/calintat/minimal">Minimal</a>.</p>
        </footer>

        

        
    </body>

</html>

